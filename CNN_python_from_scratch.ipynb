{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_python_from_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM4umJ322uOe/2pXO3G0nMH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdelatifBous/CNN-from-Scratch-/blob/main/CNN_python_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgGFb6DoqIt7",
        "outputId": "ea889f3b-8366-498f-a13c-5455174899a0"
      },
      "source": [
        "!wget https://www.ece.rice.edu/~wakin/images/lenaTest2.jpg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-11 00:22:15--  https://www.ece.rice.edu/~wakin/images/lenaTest2.jpg\n",
            "Resolving www.ece.rice.edu (www.ece.rice.edu)... 128.42.123.20\n",
            "Connecting to www.ece.rice.edu (www.ece.rice.edu)|128.42.123.20|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37926 (37K) [image/jpeg]\n",
            "Saving to: ‘lenaTest2.jpg’\n",
            "\n",
            "lenaTest2.jpg       100%[===================>]  37.04K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-03-11 00:22:16 (907 KB/s) - ‘lenaTest2.jpg’ saved [37926/37926]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd3QYvGUqMwH"
      },
      "source": [
        "import numpy as np \n",
        "from numpy import asarray \n",
        "import cv2\n",
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVDyAs-_qVd7"
      },
      "source": [
        "img = cv2.imread('lenaTest2.jpg', cv2.IMREAD_GRAYSCALE) /255\n",
        "plt.imshow(img, cmap = 'gray')\n",
        "plt.show()\n",
        "img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhqV-sPWqXcX"
      },
      "source": [
        "class Conv_op:\n",
        "  def __init__(self, num_filters, filter_size):\n",
        "    self.num_filters = num_filters\n",
        "    self.filter_size = filter_size\n",
        "    self.conv_filter = np.random.randn(num_filters, filter_size, filter_size)/ (filter_size * filter_size)\n",
        "\n",
        "  def image_region(self, image):\n",
        "    height, width = image.shape\n",
        "    self.image = image\n",
        "    for j in range(height - self.filter_size + 1 ):\n",
        "      for k in range(width - self.filter_size + 1): \n",
        "        image_patch = image[ j : (j + self.filter_size), k: (k + self.filter_size)]\n",
        "        yield image_patch, j, k \n",
        "  \n",
        "  def forward_prop(self, image):\n",
        "    height, width = image.shape\n",
        "    conv_out = np.zeros((height - self.filter_size + 1, width - self.filter_size + 1, self.num_filters))\n",
        "    for image_patch, i, j in self.image_region(image):\n",
        "      conv_out[i,j] = np.sum(image_patch*self.conv_filter, axis = (1,2))\n",
        "    return conv_out\n",
        "\n",
        "  def back_prop(self, dl_dout, learning_rate):\n",
        "    dl_df_params = np.zeros(self.conv_filter.shape)\n",
        "    for image_patch, i, j in self.image_region(self.image):\n",
        "      for k in range(self.num_filters):\n",
        "        dl_df_params[k] += image_patch*dl_dout[i,j,k]\n",
        "\n",
        "      # filter params update \n",
        "    self.conv_filter -= learning_rate*dl_df_params\n",
        "    return dl_df_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsMad9nDqhcK",
        "outputId": "d81d239f-f2a2-4c54-e533-e10ad811f1cb"
      },
      "source": [
        "conn = Conv_op(18,7)\n",
        "out = conn.forward_prop(img)\n",
        "out.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 506, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReldqP8jqzTp"
      },
      "source": [
        "plt.imshow(out[:,:,17], cmap = 'gray') # we have 18 images\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsWl3bnYq04W"
      },
      "source": [
        "class Max_Pool:\n",
        "  def __init__(self, filter_size):\n",
        "    self.filter_size = filter_size\n",
        "\n",
        "  def image_region(self, image):\n",
        "    new_height = image.shape[0] // self.filter_size\n",
        "    new_width = image.shape[1] // self.filter_size\n",
        "    self.image = image \n",
        "\n",
        "    for i in range(new_height):\n",
        "      for j in range(new_width):\n",
        "        image_patch = image[(i*self.filter_size) : (i*self.filter_size + self.filter_size) , (j*self.filter_size) : (j*self.filter_size + self.filter_size)]\n",
        "        yield image_patch, i, j\n",
        "\n",
        "  def forward_prop(self, image):\n",
        "    height, width, num_filters = image.shape\n",
        "    output = np.zeros((height // self.filter_size, width // self.filter_size, num_filters))\n",
        "\n",
        "    for image_patch , i, j in self.image_region(image):\n",
        "      output[i,j] = np.amax(image_patch, axis = (0,1))\n",
        "\n",
        "    return output\n",
        "\n",
        "  def back_prop(self, dl_dout):\n",
        "    dl_dmax_pool = np.zeros(self.image.shape)\n",
        "    for image_patch, i, j in self.image_region(self.image):\n",
        "      height, width, num_filters = image_patch.shape\n",
        "      maximum_val = np.amax(image_patch, axis = (0,1))\n",
        "\n",
        "      for i1 in range(height):\n",
        "        for j1 in range(width):\n",
        "          for k1 in range(num_filters):\n",
        "            if image_patch[i1, j1, k1] == maximum_val[k1]:\n",
        "              dl_dmax_pool[i*self.filter_size + i1 , j*self.filter_size + j1, k1] = dl_dout[i, j, k1]\n",
        "\n",
        "      return dl_dmax_pool"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBujgDleq5D3",
        "outputId": "0eca9b65-28c6-4850-90d4-c8b350275dbd"
      },
      "source": [
        "conn2 = Max_Pool(4)\n",
        "out2 = conn2.forward_prop(out)\n",
        "out2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(126, 126, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us7dr-g3q74e"
      },
      "source": [
        "plt.imshow(out2[:,:,17], cmap = 'gray') # we have 18 images\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-2cJ_JxrA6P"
      },
      "source": [
        "class Softmax:\n",
        "  def __init__(self, input_node, softmax_node):\n",
        "    self.weight = np.random.randn(input_node, softmax_node)/input_node\n",
        "    self.bias = np.zeros(softmax_node)\n",
        "\n",
        "  def forward_prop(self, image):\n",
        "\n",
        "    self.orig_im_shape = image.shape # used in backprop \n",
        "    image_modified = image.flatten()\n",
        "    self.modified_input = image_modified # to be used in backprop \n",
        "    output_val = np.dot(image_modified, self.weight) + self.bias\n",
        "    self.out = output_val \n",
        "    exp_out = np.exp(output_val)\n",
        "    return exp_out/np.sum(exp_out, axis = 0) \n",
        "\n",
        "  def back_prop(self, dl_dout, learning_rate):\n",
        "  \tfor i, grad in enumerate(dl_dout):\n",
        "  \t\tif grad == 0:\n",
        "  \t\t\tcontinue\n",
        "\n",
        "  \ttransformation_eq = np.exp(self.out)\n",
        "  \tS_total = np.sum(transformation_eq)\n",
        "\n",
        "  \t# Gradients with respect to out (z)\n",
        "  \tdy_dz = -transformation_eq[i]*transformation_eq / (S_total **2)\n",
        "  \tdy_dz[i] = transformation_eq[i]*(S_total - transformation_eq[i]) / (S_total **2)\n",
        "\n",
        "  \t# Gradiente of totals against weights/biases/input\n",
        "  \tdz_dw = self.modified_input\n",
        "  \tdz_db = 1\n",
        "  \tdz_d_inp = self.weight\n",
        "\n",
        "  \t# Gradients of loss against totals \n",
        "  \tdl_dz = grad * dy_dz\n",
        "\n",
        "  \t# Gradients of loss against weights/biases/input\n",
        "  \tdl_dw = dz_dw[np.newaxis].T @ dl_dz[np.newaxis]\n",
        "  \tdl_db = dl_dz * dz_db\n",
        "  \tdl_d_inp = dz_d_inp @ dl_dz\n",
        "\n",
        "  \t# update weights and biases \n",
        "  \tself.weight -= learning_rate * dl_dw\n",
        "  \tself.bias -= learning_rate * dl_db\n",
        "\n",
        "  \treturn dl_d_inp.reshape(self.orig_im_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcoHUj7NrPh6"
      },
      "source": [
        "conn3 = Softmax(54*54*18, 10)\n",
        "out3 = conn3.forward_prop(out2)\n",
        "print(out3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FRzBuSXv9aI",
        "outputId": "3a7f1377-a87a-473f-d5c6-4e078cdb682a"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQvZhPRIwDEk"
      },
      "source": [
        "train_images = X_train[:1500]\n",
        "train_labels = y_train[:1500]\n",
        "test_images = X_test[:1500]\n",
        "test_labels = y_test[:1500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDBXMGVzwFFd"
      },
      "source": [
        "conv = Conv_op(8,3)                   # 28*28*1  ->  26*26*8\n",
        "pool = Max_Pool(2)                    # 26*26*8  ->  13*13*8\n",
        "softmax = Softmax(13 * 13 * 8, 10)    # 13*13*8  ->  10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9Z7LYvVwryN"
      },
      "source": [
        "def cnn_forward_prop(image, label):\n",
        "\n",
        "\tout_p = conv.forward_prop((image / 255) - 0.5)\n",
        "\tout_p = pool.forward_prop(out_p)\n",
        "\tout_p = softmax.forward_prop(out_p)\n",
        "\n",
        "\t# Calculate cross-entropy loss and accuracy.\n",
        "\tcross_ent_loss = -np.log(out_p[label])\n",
        "\taccuracy_eval = 1 if np.argmax(out_p) == label else 0\n",
        "\n",
        "\treturn out_p, cross_ent_loss, accuracy_eval\n",
        "\n",
        "\n",
        "def training_cnn(image, label, learn_rate=0.005):\n",
        "\n",
        "\t# Forward \n",
        "\tout, loss, acc = cnn_forward_prop(image, label)\n",
        "\n",
        "\t# Calculate initial gradinent\n",
        "\tgradinent = np.zeros(10)\n",
        "\tgradinent[label] = -1 / out[label]\n",
        "\n",
        "\t# Backprop \n",
        "\tgrad_back = softmax.back_prop(gradinent, learn_rate)\n",
        "\tgrad_back = pool.back_prop(grad_back)\n",
        "\tgrad_back = conv.back_prop(grad_back, learn_rate)\n",
        "\n",
        "\treturn loss, acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewzy2MbWwwdK",
        "outputId": "eda5fe9a-139d-4049-df91-7a135625e2e2"
      },
      "source": [
        "for epoch1 in range(4):\n",
        "\tprint('Epoch %d ----->' % (epoch1 + 1))\n",
        "\n",
        "\t# Shuffle the training data \n",
        "\tshuffle_data = np.random.permutation(len(train_images))\n",
        "\ttrain_images = train_images[shuffle_data]\n",
        "\ttrain_labels = train_labels[shuffle_data]\n",
        "\n",
        "\t# Training the CNN\n",
        "\tloss = 0\n",
        "\tnum_correct = 0 \n",
        "\tfor i, (im, label) in enumerate(zip(train_images, train_labels)): \n",
        "\t\tif i % 100 == 0:\n",
        "\t\t\tprint('%d steps out of 100 steps: Average Loss %.3f and Accuracy: %d%%' %(i + 1, loss / 100, num_correct) )\n",
        "\t\t\tloss = 0 \n",
        "\t\t\tnum_correct = 0 \n",
        "\t\tll, accu = training_cnn(im, label)\n",
        "\t\tloss += ll \n",
        "\t\tnum_correct += accu\n",
        "\n",
        "# Testing the CNN \n",
        "print('**Testing phase')\n",
        "loss = 0 \n",
        "num_correct = 0 \n",
        "for im, label in zip(test_images, test_labels):\n",
        "\t_, ll, accu = cnn_forward_prop(im, label)\n",
        "\tloss += ll \n",
        "\tnum_correct += accu\n",
        "\n",
        "num_tests = len(test_images)\n",
        "print( 'Test Loss:', loss / num_tests)\n",
        "print( 'Test Accuracy:', num_correct / num_tests)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 ----->\n",
            "1 steps out of 100 steps: Average Loss 0.000 and Accuracy: 0%\n",
            "101 steps out of 100 steps: Average Loss 2.330 and Accuracy: 3%\n",
            "201 steps out of 100 steps: Average Loss 2.384 and Accuracy: 13%\n",
            "301 steps out of 100 steps: Average Loss 2.798 and Accuracy: 11%\n",
            "401 steps out of 100 steps: Average Loss 3.043 and Accuracy: 10%\n",
            "501 steps out of 100 steps: Average Loss 3.231 and Accuracy: 13%\n",
            "601 steps out of 100 steps: Average Loss 3.446 and Accuracy: 14%\n",
            "701 steps out of 100 steps: Average Loss 3.708 and Accuracy: 11%\n",
            "801 steps out of 100 steps: Average Loss 3.947 and Accuracy: 7%\n",
            "901 steps out of 100 steps: Average Loss 4.112 and Accuracy: 6%\n",
            "1001 steps out of 100 steps: Average Loss 3.988 and Accuracy: 12%\n",
            "1101 steps out of 100 steps: Average Loss 4.087 and Accuracy: 12%\n",
            "1201 steps out of 100 steps: Average Loss 4.179 and Accuracy: 13%\n",
            "1301 steps out of 100 steps: Average Loss 4.624 and Accuracy: 5%\n",
            "1401 steps out of 100 steps: Average Loss 4.192 and Accuracy: 16%\n",
            "Epoch 2 ----->\n",
            "1 steps out of 100 steps: Average Loss 0.000 and Accuracy: 0%\n",
            "101 steps out of 100 steps: Average Loss 4.497 and Accuracy: 11%\n",
            "201 steps out of 100 steps: Average Loss 4.670 and Accuracy: 9%\n",
            "301 steps out of 100 steps: Average Loss 4.628 and Accuracy: 12%\n",
            "401 steps out of 100 steps: Average Loss 4.915 and Accuracy: 8%\n",
            "501 steps out of 100 steps: Average Loss 4.874 and Accuracy: 8%\n",
            "601 steps out of 100 steps: Average Loss 4.586 and Accuracy: 13%\n",
            "701 steps out of 100 steps: Average Loss 4.824 and Accuracy: 11%\n",
            "801 steps out of 100 steps: Average Loss 5.038 and Accuracy: 8%\n",
            "901 steps out of 100 steps: Average Loss 5.018 and Accuracy: 9%\n",
            "1001 steps out of 100 steps: Average Loss 4.793 and Accuracy: 13%\n",
            "1101 steps out of 100 steps: Average Loss 4.978 and Accuracy: 11%\n",
            "1201 steps out of 100 steps: Average Loss 5.393 and Accuracy: 5%\n",
            "1301 steps out of 100 steps: Average Loss 5.012 and Accuracy: 12%\n",
            "1401 steps out of 100 steps: Average Loss 5.060 and Accuracy: 12%\n",
            "Epoch 3 ----->\n",
            "1 steps out of 100 steps: Average Loss 0.000 and Accuracy: 0%\n",
            "101 steps out of 100 steps: Average Loss 5.395 and Accuracy: 8%\n",
            "201 steps out of 100 steps: Average Loss 5.218 and Accuracy: 10%\n",
            "301 steps out of 100 steps: Average Loss 5.520 and Accuracy: 6%\n",
            "401 steps out of 100 steps: Average Loss 5.091 and Accuracy: 14%\n",
            "501 steps out of 100 steps: Average Loss 5.252 and Accuracy: 10%\n",
            "601 steps out of 100 steps: Average Loss 5.152 and Accuracy: 14%\n",
            "701 steps out of 100 steps: Average Loss 5.524 and Accuracy: 8%\n",
            "801 steps out of 100 steps: Average Loss 5.584 and Accuracy: 8%\n",
            "901 steps out of 100 steps: Average Loss 5.306 and Accuracy: 12%\n",
            "1001 steps out of 100 steps: Average Loss 5.601 and Accuracy: 7%\n",
            "1101 steps out of 100 steps: Average Loss 5.520 and Accuracy: 11%\n",
            "1201 steps out of 100 steps: Average Loss 5.375 and Accuracy: 12%\n",
            "1301 steps out of 100 steps: Average Loss 5.756 and Accuracy: 7%\n",
            "1401 steps out of 100 steps: Average Loss 5.225 and Accuracy: 14%\n",
            "Epoch 4 ----->\n",
            "1 steps out of 100 steps: Average Loss 0.000 and Accuracy: 0%\n",
            "101 steps out of 100 steps: Average Loss 5.553 and Accuracy: 11%\n",
            "201 steps out of 100 steps: Average Loss 5.680 and Accuracy: 9%\n",
            "301 steps out of 100 steps: Average Loss 5.700 and Accuracy: 9%\n",
            "401 steps out of 100 steps: Average Loss 5.614 and Accuracy: 11%\n",
            "501 steps out of 100 steps: Average Loss 5.726 and Accuracy: 9%\n",
            "601 steps out of 100 steps: Average Loss 5.788 and Accuracy: 8%\n",
            "701 steps out of 100 steps: Average Loss 5.652 and Accuracy: 11%\n",
            "801 steps out of 100 steps: Average Loss 5.862 and Accuracy: 8%\n",
            "901 steps out of 100 steps: Average Loss 5.650 and Accuracy: 11%\n",
            "1001 steps out of 100 steps: Average Loss 5.781 and Accuracy: 9%\n",
            "1101 steps out of 100 steps: Average Loss 5.718 and Accuracy: 11%\n",
            "1201 steps out of 100 steps: Average Loss 5.517 and Accuracy: 14%\n",
            "1301 steps out of 100 steps: Average Loss 5.773 and Accuracy: 11%\n",
            "1401 steps out of 100 steps: Average Loss 5.853 and Accuracy: 9%\n",
            "**Testing phase\n",
            "Test Loss: 5.907487502057495\n",
            "Test Accuracy: 0.096\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}